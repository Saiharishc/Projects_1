Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties. 
This selects a few samples randomly instead of whole data set for each iteration.
Gradient descent types 1. Batch , 2. Stochastic , 3. Mini Batch
